# -*- coding: utf-8 -*-
"""TreeModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cFflzalKqowBUHhWzR1rj7Arf2Bs09Nb
"""

import numpy as np
import pandas as pd
from sklearn import datasets
from sklearn import tree
from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler
from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor,GradientBoostingRegressor, VotingRegressor
from sklearn.model_selection import train_test_split,GridSearchCV, KFold, RandomizedSearchCV
from sklearn.pipeline import make_pipeline



dataset = datasets.load_boston()
x_data = np.array(dataset.data, dtype='f8')
y_data = np.array(dataset.target, dtype='f8')



x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=2152)



# 교차검증
kfold = KFold(n_splits=5, shuffle=True, random_state=2152)
kfold.get_n_splits(x_train,y_train)


# 디시즌트리 피처임포턴스
DT = tree.DecisionTreeRegressor()

DT = DT.fit(x_train, y_train)

print(DT.feature_importances_)

# 랜덤포레스트 피처임포턴스
RF = RandomForestRegressor(random_state=2152)

RF = RF.fit(x_train, y_train)

print(RF.feature_importances_)

# 아다부스트 피처임포턴스
AB = AdaBoostRegressor(random_state=2152)

AB = AB.fit(x_train, y_train)

print(AB.feature_importances_)


# 그레디언트 부스트 피처임포턴스
GB = GradientBoostingRegressor(random_state=2152)

GB = GB.fit(x_train, y_train)

print(GB.feature_importances_)




# 모델 앙상블 (voting)
ensemble = VotingRegressor(estimators=[('DecisionTree',DT),('RandomForest',RF),('AdaBoost',AB),('GradientBoost',GB)])


# 하이퍼파라미터 설정 (학습속도 문제로 2개씩만)
parameters = [{
    'DecisionTree__max_depth':[4,6], 
    'RandomForest__max_depth':[4,6],
    'RandomForest__n_estimators':[50,100],
    'AdaBoost__n_estimators':[50,100],
    'GradientBoost__max_depth':[4,6],
    'GradientBoost__n_estimators':[50,100]

}]


# 그리드서치 모델
model = GridSearchCV(
    estimator=ensemble, 
    param_grid=parameters, 
    cv=kfold,
    n_jobs=4
    )


# ensemble.get_params().keys() 으로 파라미터 확인



# scaler 4개
scaler = [MinMaxScaler(),StandardScaler(),RobustScaler(),MaxAbsScaler()]


# scaler를 각각 차례대로 그리드서치 모델로 fit, score
for sc in scaler:
  x_data = np.array(dataset.data, dtype='f8')
  y_data = np.array(dataset.target, dtype='f8')
  x_data = sc.fit_transform(x_data)
  x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=2152)
  model.fit(x_train, y_train)
  print(f"Scaler : {sc} \nBestScore : {model.best_score_} \nBestParams : {model.best_params_}")
  print(f"ModelScore : {model.score(x_test,y_test)} \n ==========")




# 결과
"""

Scaler : MinMaxScaler(copy=True, feature_range=(0, 1)) 
BestScore : 0.8254755887006932 
BestParams : {'AdaBoost__n_estimators': 50, 'DecisionTree__max_depth': 6, 'GradientBoost__max_depth': 4, 'GradientBoost__n_estimators': 100, 'RandomForest__max_depth': 6, 'RandomForest__n_estimators': 50}
ModelScore : 0.8925245533916384 
 ==========
Scaler : StandardScaler(copy=True, with_mean=True, with_std=True) 
BestScore : 0.8257818512234415 
BestParams : {'AdaBoost__n_estimators': 50, 'DecisionTree__max_depth': 6, 'GradientBoost__max_depth': 4, 'GradientBoost__n_estimators': 100, 'RandomForest__max_depth': 6, 'RandomForest__n_estimators': 100}
ModelScore : 0.8919608904181375 
 ==========
Scaler : RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,
             with_scaling=True) 
BestScore : 0.8247918165814984 
BestParams : {'AdaBoost__n_estimators': 50, 'DecisionTree__max_depth': 6, 'GradientBoost__max_depth': 4, 'GradientBoost__n_estimators': 100, 'RandomForest__max_depth': 6, 'RandomForest__n_estimators': 100}
ModelScore : 0.8859308932974114 
 ==========
Scaler : MaxAbsScaler(copy=True) 
BestScore : 0.8244735294895763 
BestParams : {'AdaBoost__n_estimators': 100, 'DecisionTree__max_depth': 6, 'GradientBoost__max_depth': 4, 'GradientBoost__n_estimators': 50, 'RandomForest__max_depth': 6, 'RandomForest__n_estimators': 100}
ModelScore : 0.8905569241946933 
 ==========

"""


# 랜덤서치 하이퍼파라미터
parameters2 = [{
    'DecisionTree__max_depth':[4,6,8], 
    'RandomForest__max_depth':[4,6,8],
    'RandomForest__n_estimators':[50,100,150],
    'AdaBoost__n_estimators':[50,100,150],
    'GradientBoost__max_depth':[4,6,8],
    'GradientBoost__n_estimators':[50,100,150]

}]

# 랜덤서치 모델 (속도문제로 20번만)
model2 = RandomizedSearchCV(
    estimator=ensemble,
    param_distributions = parameters2, 
    cv=kfold,
    n_iter=20,
    n_jobs=4
    )

# scaler 4개
scaler = [MinMaxScaler(),StandardScaler(),RobustScaler(),MaxAbsScaler()]

# 랜덤서치후 fit, score 확인
for sc in scaler:
  x_data = np.array(dataset.data, dtype='f8')
  y_data = np.array(dataset.target, dtype='f8')
  x_data = sc.fit_transform(x_data)
  x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=2152)
  model2.fit(x_train, y_train)
  print(f"Scaler : {sc} \nBestScore : {model2.best_score_} \nBestParams : {model2.best_params_}")
  print(f"ModelScore : {model2.score(x_test,y_test)} \n ==========")


# 결과
"""
  Scaler : MinMaxScaler(copy=True, feature_range=(0, 1)) 
BestScore : 0.8267439841654742 
BestParams : {'RandomForest__n_estimators': 150, 'RandomForest__max_depth': 6, 'GradientBoost__n_estimators': 100, 'GradientBoost__max_depth': 4, 'DecisionTree__max_depth': 6, 'AdaBoost__n_estimators': 150}
ModelScore : 0.8933073091803947 
 ==========
Scaler : StandardScaler(copy=True, with_mean=True, with_std=True) 
BestScore : 0.8248214085075027 
BestParams : {'RandomForest__n_estimators': 150, 'RandomForest__max_depth': 8, 'GradientBoost__n_estimators': 100, 'GradientBoost__max_depth': 4, 'DecisionTree__max_depth': 8, 'AdaBoost__n_estimators': 50}
ModelScore : 0.8832947372494151 
 ==========
Scaler : RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,
             with_scaling=True) 
BestScore : 0.8172226671216208 
BestParams : {'RandomForest__n_estimators': 50, 'RandomForest__max_depth': 8, 'GradientBoost__n_estimators': 50, 'GradientBoost__max_depth': 4, 'DecisionTree__max_depth': 6, 'AdaBoost__n_estimators': 150}
ModelScore : 0.8932416540513468 
 ==========
Scaler : MaxAbsScaler(copy=True) 
BestScore : 0.8193430866329928 
BestParams : {'RandomForest__n_estimators': 100, 'RandomForest__max_depth': 4, 'GradientBoost__n_estimators': 150, 'GradientBoost__max_depth': 4, 'DecisionTree__max_depth': 6, 'AdaBoost__n_estimators': 150}
ModelScore : 0.8912125966167447 
 ==========

 """