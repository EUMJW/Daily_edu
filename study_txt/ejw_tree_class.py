# -*- coding: utf-8 -*-
"""tree_class.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oYltl2njer-TI9sokafNoCkcT4sDQtVw
"""

import numpy as np
import pandas as pd
from sklearn import datasets
from sklearn import tree
from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler
from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor,GradientBoostingRegressor, VotingRegressor
from sklearn.model_selection import train_test_split,GridSearchCV, KFold, RandomizedSearchCV
from sklearn.pipeline import make_pipeline

dataset = datasets.load_boston()
x_data = np.array(dataset.data, dtype='f8')
y_data = np.array(dataset.target, dtype='f8')

class Modeling:
  def __init__(self,x_data,y_data):
    self.x_data = x_data
    self.y_data = y_data

  def minmax(self):
    sc = MinMaxScaler()
    self.x_data = sc.fit_transform(self.x_data)

  def standard(self):
    sc = StandardScaler()
    self.x_data = sc.fit_transform(self.x_data)

  def robust(self):
    sc = RobustScaler()
    self.x_data = sc.fit_transform(self.x_data)

  def maxabs(self):
    sc = MaxAbsScaler()
    self.x_data = sc.fit_transform(self.x_data)

  def split(self,size):
    self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.x_data, self.y_data, test_size=size, random_state=2152)
  
  def k_fold(self, n_splits):
    self.kfold = KFold(n_splits=n_splits, shuffle=True, random_state=2152)

  def make_model(self):
    self.DT = tree.DecisionTreeRegressor()
    self.RF = RandomForestRegressor(random_state=2152)
    self.AB = AdaBoostRegressor(n_estimators=60, random_state=2152)
    self.GB = GradientBoostingRegressor(n_estimators=100, random_state=2152)
    self.ensemble = VotingRegressor(estimators=[('DecisionTree',self.DT),('RandomForest',self.RF),('AdaBoost',self.AB),('GradientBoost',self.GB)])

  def make_param(self,DT_maxdepth, RF_maxdepth, RF_n_estimators, AB_n_estimators, GB_maxdepth, GB_n_estimators):
    self.parameters = [{
    'DecisionTree__max_depth':DT_maxdepth, 
    'RandomForest__max_depth':RF_maxdepth,
    'RandomForest__n_estimators':RF_n_estimators,
    'AdaBoost__n_estimators':AB_n_estimators,
    'GradientBoost__max_depth':GB_maxdepth,
    'GradientBoost__n_estimators':GB_n_estimators
    }]

  def gridsearch(self):
    self.model = GridSearchCV(
          estimator=self.ensemble, 
          param_grid=self.parameters, 
          cv=self.kfold,
          n_jobs=-1
    )
     
    self.model.fit(self.x_train, self.y_train)
    print(f"\nBestScore : {self.model.best_score_} \nBestParams : {self.model.best_params_}")
    print(f"ModelScore : {self.model.score(self.x_test,self.y_test)} \n ==========")

  def randomsearch(self,n_iter):
    self.model = RandomizedSearchCV(
          estimator=self.ensemble, 
          param_distributions=self.parameters, 
          cv=self.kfold,
          n_iter=n_iter,
          n_jobs=-1
      )
    self.model.fit(self.x_train, self.y_train)
    print(f"\nBestScore : {self.model.best_score_} \nBestParams : {self.model.best_params_}")
    print(f"ModelScore : {self.model.score(self.x_test,self.y_test)} \n ==========")



model = Modeling(x_data, y_data)

model.minmax()

model.split(0.3)

model.k_fold(5)

model.make_model()

model.make_param([4,7],[4,6],[50,100],[50,100],[4,6],[50,100])

model.randomsearch(10)

model.gridsearch()

