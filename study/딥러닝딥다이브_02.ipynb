{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  loss  1.6038203  prediction  [[3 3 3 3 3 3]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  llllll\n",
      "1  loss  1.5147628  prediction  [[3 3 3 3 3 3]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  llllll\n",
      "2  loss  1.423818  prediction  [[3 3 3 3 3 3]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  llllll\n",
      "3  loss  1.337347  prediction  [[3 3 3 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  lllllo\n",
      "4  loss  1.2325989  prediction  [[3 3 3 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  lllllo\n",
      "5  loss  1.1055201  prediction  [[2 2 3 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  eelllo\n",
      "6  loss  0.98688823  prediction  [[2 2 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  eeello\n",
      "7  loss  0.864604  prediction  [[2 2 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  eeello\n",
      "8  loss  0.77505237  prediction  [[2 2 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  eeello\n",
      "9  loss  0.68510276  prediction  [[2 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ehello\n",
      "10  loss  0.60618824  prediction  [[2 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ehello\n",
      "11  loss  0.5334645  prediction  [[2 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ehello\n",
      "12  loss  0.47314024  prediction  [[2 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ehello\n",
      "13  loss  0.41582286  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "14  loss  0.36483586  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "15  loss  0.31952688  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "16  loss  0.2773722  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "17  loss  0.23843123  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "18  loss  0.20262308  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "19  loss  0.1695853  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "20  loss  0.13919647  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "21  loss  0.111730605  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "22  loss  0.08809645  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "23  loss  0.068858504  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "24  loss  0.052665666  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "25  loss  0.03966398  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "26  loss  0.030118227  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "27  loss  0.02318076  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "28  loss  0.018089464  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "29  loss  0.014315058  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "30  loss  0.011486608  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "31  loss  0.009340299  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "32  loss  0.0076882653  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "33  loss  0.00639797  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "34  loss  0.005378494  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "35  loss  0.004567548  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "36  loss  0.003921283  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "37  loss  0.0034064048  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "38  loss  0.0029963471  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "39  loss  0.0026689358  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "40  loss  0.002405729  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "41  loss  0.0021913217  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "42  loss  0.0020130882  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "43  loss  0.0018611372  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "44  loss  0.0017282796  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "45  loss  0.0016101127  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "46  loss  0.0015044478  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "47  loss  0.0014103623  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "48  loss  0.0013274467  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n",
      "49  loss  0.0012551311  prediction  [[1 0 2 3 3 4]]  Y:   [[1, 0, 2, 3, 3, 4]]\n",
      " \tPrediction string :  ihello\n"
     ]
    }
   ],
   "source": [
    "# cnn : 이미지 한장한장을 학습하는데 유리\n",
    "# rnn : 시계열 데이터를 학습하는데 유리\n",
    "# 언어나 영상같은 이미지 등에도 적용하기 좋음\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "# RNN keep weights in the memory\n",
    "# 값을 초기화 시켜줘서 \n",
    "\n",
    "idx2char = ['h','i','e','l','o']\n",
    "x_data = [[0,1,0,2,3,3]]\n",
    "# 입력할 단어 -> h i h e l l\n",
    "y_data = [[1,0,2,3,3,4]]\n",
    "# 예측할 단어 -> i h e l l o\n",
    "\n",
    "x_one_hot = [[[1,0,0,0,0], # h 0\n",
    "             [0,1,0,0,0],  # i 1\n",
    "             [1,0,0,0,0],  # h 0\n",
    "             [0,0,1,0,0],  # e 2\n",
    "             [0,0,0,1,0],  # l 3\n",
    "             [0,0,0,1,0]]] # l 3\n",
    "# 문자는 수치값이 없어서 예측하기 매우 어렵다\n",
    "# 따라서 벡터라이즈 해준다\n",
    "\n",
    "\n",
    "\n",
    "num_class = 5\n",
    "\n",
    "input_dim = 5\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "sequence_length = 6\n",
    "# cell의 갯수\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, sequence_length, input_dim])\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "# y는 인덱스값을 예측하려고 해서 int로 넣음\n",
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=5, state_is_tuple=True)\n",
    "# LSTM에 가중치에 관한 모든게 들어가있음\n",
    "# 노드갯수 5 다음스테이트로 넘어가는거 true\n",
    "# x원핫 (1,5) * 가중치 (5, x ) = (1,x) 가 되는데\n",
    "# 이때 x에 해당하는 값이 num_units\n",
    "\n",
    "init_state = cell.zero_state(batch_size, tf.float32)\n",
    "#초기 스테이트는 0으로 받겠다\n",
    "# [0,0,0,0,0] 으로 받겠다\n",
    "\n",
    "\n",
    "\n",
    "outputs, _state = tf.nn.dynamic_rnn(cell, X, initial_state = init_state, dtype = tf.float32)\n",
    "\n",
    "\n",
    "X_for_fc = tf.reshape(outputs, [-1, 5])\n",
    "outputs = tf.contrib.layers.fully_connected(inputs=X_for_fc,\n",
    "                                           num_outputs=num_class,\n",
    "                                           activation_fn=None)\n",
    "\n",
    "# activation_fn이 sigmoid나 relu가 아닌 none이면 linear regression 하겠다는 뜻\n",
    "# 여기서 activation을 안넣은 이유는 0,1,2,3,4의 인덱스값을 리턴해야하기때문에\n",
    "\n",
    "\n",
    "\n",
    "outputs = tf.reshape(outputs, [batch_size, sequence_length, num_class])\n",
    "\n",
    "weight = tf.ones([batch_size, sequence_length])\n",
    "# ones : 1로 채워라\n",
    "# 이 가중치는 실제 데이터와 예측 데이터간에 차이를 구할때 한 시퀀스 안에 각각의 값에 대해 얼마나 가중치를 둘것인가\n",
    "\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits = outputs,\n",
    "                                                targets = Y,\n",
    "                                                weights = weight)\n",
    "# seq2seq : [0.8, 0.2, 0.7, -1, 3, 3] 과 [1,0,2,3,3,4] 의 시퀀스간 거리\n",
    "\n",
    "\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "prediction = tf.argmax(outputs, axis = 2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(50):\n",
    "        l, _ = sess.run([loss, train], feed_dict={X:x_one_hot, Y:y_data})\n",
    "        result = sess.run(prediction, feed_dict={X:x_one_hot})\n",
    "        print(i,' loss ',l, ' prediction ', result, ' Y:  ',y_data )\n",
    "        \n",
    "        result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "        print(' \\tPrediction string : ',''.join(result_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist를 rnn을 통해 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Cost: 0.6756589013240828\n",
      "Epoch: 2, Cost: 0.2721867805698535\n",
      "Epoch: 3, Cost: 0.21016050758825885\n",
      "Epoch: 4, Cost: 0.17866291010226973\n",
      "Epoch: 5, Cost: 0.15424367975191772\n",
      "Epoch: 6, Cost: 0.14235541267463783\n",
      "Epoch: 7, Cost: 0.12906600953468347\n",
      "Epoch: 8, Cost: 0.12235905398508325\n",
      "Epoch: 9, Cost: 0.11201202152144941\n",
      "Epoch: 10, Cost: 0.11104967416913218\n",
      "Learning Finished\n",
      "Accuracy of Test data: 1.0\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "input_dim = 28\n",
    "sequence_length = 28\n",
    "num_class = 10\n",
    "batch_size = 128\n",
    "hidden_layer_size = 128\n",
    "training_epochs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, sequence_length, input_dim])\n",
    "Y = tf.placeholder(tf.float32, [None, num_class])\n",
    "\n",
    "\n",
    "rnn_cell = tf.contrib.rnn.BasicRNNCell(hidden_layer_size)\n",
    "outputs, _ = tf.nn.dynamic_rnn(rnn_cell, X, dtype=tf.float32)\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.truncated_normal([hidden_layer_size, num_class],\n",
    "                                    mean=0, stddev=0.01))\n",
    "b = tf.Variable(tf.truncated_normal([num_class],\n",
    "                                    mean=0, stddev=0.01))\n",
    "# truncated : -1 이하, 1이상을 짤라버림\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "last_outputs = outputs[:,-1,:]\n",
    "# (n,784) 로 바꿔줌\n",
    "\n",
    "hypothesis = tf.matmul(last_outputs, W) + b\n",
    "\n",
    "\n",
    "softmax = tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y)\n",
    "cost = tf.reduce_mean(softmax)\n",
    "train = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            batch_xs = batch_xs.reshape([batch_size, sequence_length, input_dim])\n",
    "            feed_dict = {X:batch_xs, Y:batch_ys}\n",
    "            c, _ = sess.run([cost, train], feed_dict=feed_dict)\n",
    "            avg_cost += c / total_batch\n",
    "        print(\"Epoch: {}, Cost: {}\".format(epoch+1, avg_cost))\n",
    "    print(\"Learning Finished\") \n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    test_data = mnist.test.images[:batch_size].reshape((-1,sequence_length, input_dim))\n",
    "    test_label = mnist.test.labels[:batch_size]\n",
    "   \n",
    "    print(\"Accuracy of Test data: {}\".format(sess.run(accuracy, feed_dict={X:test_data,\n",
    "                                                             Y:test_label})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn - 셀이 넘어가면서 이전 데이터에 대한 영향이 점점 줄어듬\n",
    "# h1이 x1에서 인풋받아서 h2로 전달\n",
    "# h2에서는 x2값과 h1값을 인풋으로 받아서\n",
    "#  h2 = tanh(   w1*h1 + w2*x2   +   b )\n",
    "#  y2 =  w * h2  +  b\n",
    "# 이런모양이 되면서\n",
    "# h1의 값의 영향력이 줄어들고, h3에서 h1의 영향력은 더더욱 줄어들기에\n",
    "# LSTM을 만듬\n",
    "\n",
    "\n",
    "# LSTM - 이전 데이터에 대해 영향력을 높힘\n",
    "# forget 함수 - 시그모이드 함수와 h1, x2를 사용하여 이전 데이터를 받아올지, 잊어버릴지 결정\n",
    "# 이후 x2의 tanh( ) 와 더하여 영향력을 유지해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                     https://github.com/gilbutITbook/080228\n",
    "# 에서 예제 다운로드 후\n",
    "# 아나콘다 프롬프트에서 텐서플로우를 2.0.0으로 업그레이드\n",
    "\n",
    "# venv\\Scripts\\activate\n",
    "\n",
    "# pip install --upgrade Tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
